{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91904fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Parámetros básicos\n",
    "nb_train_samples = 1400\n",
    "nb_validation_samples = 400\n",
    "epochs = 40\n",
    "width_shape = 224\n",
    "height_shape = 224\n",
    "num_classes = 10\n",
    "\n",
    "# Nuevas rutas actualizadas\n",
    "train_data_dir = 'D:\\\\Escritorio\\\\Noveno semestre\\\\Electiva 3\\\\DataSet aves Organizado\\\\entrenamiento'\n",
    "validation_data_dir = 'D:\\\\Escritorio\\\\Noveno semestre\\\\Electiva 3\\\\DataSet aves Organizado\\\\validacion'\n",
    "\n",
    "# Función para crear y entrenar el modelo\n",
    "def create_and_train_vgg16_model(learning_rate, l2_regularization, batch_size):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "\n",
    "    valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(width_shape, height_shape),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = valid_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(width_shape, height_shape),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    image_input = Input(shape=(width_shape, height_shape, 3), name='image_input')\n",
    "    base_model = VGG16(input_tensor=image_input, include_top=False, weights='imagenet')\n",
    "\n",
    "    x = Flatten()(base_model.output)\n",
    "    out = Dense(num_classes, activation='softmax', kernel_regularizer='l2')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=out)\n",
    "\n",
    "    # Congelar todas las capas primero\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Desbloquear solo las últimas 4 capas convolucionales\n",
    "    for layer in base_model.layers[-4:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        'best_model.keras', monitor='val_loss', verbose=1,\n",
    "        save_best_only=True, mode='min'\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', patience=5, verbose=1,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "    return model_history\n",
    "\n",
    "# Hiperparámetros a probar\n",
    "learning_rates = [0.0001, 0.0005]\n",
    "l2_regularizations = [1e-4, 1e-5]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for l2_regularization in l2_regularizations:\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"\\nEntrenando con lr={learning_rate}, l2={l2_regularization}, batch_size={batch_size}...\")\n",
    "            model_history = create_and_train_vgg16_model(\n",
    "                learning_rate, l2_regularization, batch_size\n",
    "            )\n",
    "            val_accuracy = np.max(model_history.history['val_accuracy'])\n",
    "\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_hyperparams = {\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'l2_regularization': l2_regularization,\n",
    "                    'batch_size': batch_size,\n",
    "                    'val_accuracy': val_accuracy\n",
    "                }\n",
    "\n",
    "print(\"\\n--- Mejores hiperparámetros encontrados ---\")\n",
    "print(best_hyperparams)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
